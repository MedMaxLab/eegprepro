{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a44c83ef-a139-44a9-a53d-ab1cd54b94db",
   "metadata": {},
   "source": [
    "# BIDSAlign Matlab to Pickle converter\n",
    "\n",
    "This notebook converts all mat files created with the BIDSAlign library to pickle\n",
    "files. \n",
    "\n",
    "The reasons behind this conversion are multiple:\n",
    "\n",
    "1. It is much more efficient to load a pickle file in a Python environment \n",
    "compared to .mat files. \n",
    "2. Second, a dataset summary stored in a json file is created during the conversion. \n",
    "Inside the json file, many information can be found, such as the number of subjects, \n",
    "the number of sessions, the sampling rate, the EEG reference, \n",
    "the added channels (interpolated), the eeg template (data row --> eeg channel), \n",
    "and the label meaning (number --> condition or task). \n",
    "3. files originally grouped in several folds based on the dataset ID, \n",
    "condition or task, and preprocessing pipeline, are stored together based only on the \n",
    "preprocessing pipeline.\n",
    "\n",
    "The final result, after multiple running of this notebook for each folder with the\n",
    ".mat files, is a directory with 4 subdirectories, one for each preprocessing pipeline.\n",
    "Each folder will have all the files preprocessed with a specific preprocessing pipeline\n",
    "where each file will contain a dictionary with fields 'data' for the 2d numpy array and\n",
    "'label' for the label number (a single scalar).\n",
    "\n",
    "**additional note:** the only things to set up are the root path to all the files\n",
    "preprocessed with bidsalign and the output path. The datasets path is expected to \n",
    "contain a set of subdirectories with name\n",
    "\n",
    "_dsxxxxxLABEL_PIPELINE_ (e.g., ds004362RHI_FILT),\n",
    "\n",
    "while the output path is expected to contain 4 subdirectories with names \n",
    "\n",
    "*raw*, *filt*, *ica*, *icasr*\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d26d21a6-7b23-441f-8c9a-895a57be7cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob \n",
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "import random\n",
    "from   scipy.io import loadmat\n",
    "import sys\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0cd3ee8-a3fc-4bf4-b705-d0ea65d634e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------- SET PATH TO DATA -------------------\n",
    "# DON'T FORGET TO PUT THE SEPARATOR AT THE END OF THE PATH\n",
    "\n",
    "path_to_data = '/path/to/data/'\n",
    "if path_to_data[-1] != os.sep:\n",
    "    path_to_data += os.sep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86c592b2-6251-40f4-b5aa-02b01a18e44c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------- SET PATH TO DATA -------------------\n",
    "# DON'T FORGET TO PUT THE SEPARATOR AT THE END OF THE PATH\n",
    "\n",
    "# ------------------------- NOTE -------------------------\n",
    "# save path must be a directory containing 4 subdirectories \n",
    "# with names associated to a specific pipeline. In particular:\n",
    "# 1. raw    --    2. filt    --    3. ica    --    4. icasr\n",
    "save_path = '/data/delpup/eegpickle/'\n",
    "if save_path[-1] != os.sep:\n",
    "    save_path += os.sep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eb51aa4-bd12-4b52-8e45-d2ba9963228a",
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = glob.glob(path_to_data + '*.mat')\n",
    "\n",
    "# sort paths according to file name\n",
    "paths = sorted(paths, \n",
    "               key = lambda x: (int(x.split(os.sep)[-1].split('_')[0]),\n",
    "                                int(x.split(os.sep)[-1].split('_')[1]),\n",
    "                                int(x.split(os.sep)[-1].split('_')[2]),\n",
    "                                int(x.split(os.sep)[-1].split('.')[0].split('_')[3])\n",
    "                               )\n",
    "              )\n",
    "\n",
    "# extract file_name \n",
    "file_names = [paths[i].split(os.sep)[-1] for i in range(len(paths))]\n",
    "\n",
    "# extract ds code\n",
    "ds_code = path_to_data.split(os.sep)[-2][:8]\n",
    "\n",
    "# extract preprocessing modality\n",
    "prepro_mode = path_to_data.split(os.sep)[-2].split('_')[-1]\n",
    "\n",
    "# print ds_code and prepro_mode to double check that everything was extracted correctly\n",
    "print(ds_code)\n",
    "print(prepro_mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6ecf7db-6df6-4985-9ca7-bf60e80004b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# double check cell. It verifies that file names and paths are aligned\n",
    "for i in [random.randint(0,len(file_names)-1) for i in range(5)]:\n",
    "    print(paths[i],file_names[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "581d414a-7716-4ae5-a04b-f0cb34584437",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create pickle files \n",
    "if prepro_mode.casefold() == 'icasr':\n",
    "    save_path += 'icasr/'\n",
    "elif prepro_mode.casefold() == 'filt':\n",
    "    save_path += 'filt/'\n",
    "elif prepro_mode.casefold() == 'raw':\n",
    "    save_path += 'raw/'\n",
    "elif prepro_mode.casefold() == 'ica':\n",
    "    save_path += 'ica/'\n",
    "\n",
    "# double check that the extracted save path is correct\n",
    "print(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2ffc518-2471-451c-a495-838ed195e976",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Task: Eyes Open - Eyes Closed \n",
    "if ds_code == 'ds004148':\n",
    "    data = loadmat(paths[0], simplify_cells = True)\n",
    "    np.save('EoecClassification/Summary/template.npy',data['DATA_STRUCT']['template'])\n",
    "    np.save('EoecClassification/Summary/channels_interpolated.npy',\n",
    "            data['DATA_STRUCT']['pad_file'])\n",
    "    dataset_info = {'dataset_id': 2, 'tot_subjects': 60, 'tot_sessions': 2,\n",
    "                    'sampling_rate': 250, 'reference': 'Common Average',\n",
    "                    'template': data['DATA_STRUCT']['template'].tolist(),\n",
    "                    'channels_interpolated': data['DATA_STRUCT']['pad_file'].tolist(),\n",
    "                    'added_channels': data['DATA_STRUCT']['template'] \\\n",
    "                                      [data['DATA_STRUCT']['pad_file']>0].tolist(),\n",
    "                    'labels' : {0: 'EC', 1: 'EO'},\n",
    "                   }\n",
    "    with open('EoecClassification/Summary/dataset_info.json', 'w') as json_file:\n",
    "        json.dump(dataset_info, json_file)        \n",
    "    for i in tqdm.tqdm(range(len(paths))):\n",
    "        data = loadmat(paths[i], simplify_cells = True)\n",
    "        label = data['DATA_STRUCT']['label_group']\n",
    "        label = 0 if label=='EC' else 1\n",
    "        eeg = {'data': data['DATA_STRUCT']['data'], 'label': label }\n",
    "        with open(save_path + file_names[i].split('.')[0] + '.pickle', 'wb') as handle:\n",
    "            pickle.dump(eeg, handle, protocol = pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "# Task: Alzheimer - Frontotemporal Dementia - Control\n",
    "elif ds_code == 'ds004504':\n",
    "    data = loadmat(paths[0], simplify_cells = True)\n",
    "    np.save('AlzClassification/Summary/template.npy',data['DATA_STRUCT']['template'])\n",
    "    np.save('AlzClassification/Summary/channels_interpolated.npy',\n",
    "            data['DATA_STRUCT']['pad_file'])\n",
    "    dataset_info = {'dataset_id': 10, 'tot_subjects': 88, 'tot_sessions': 1,\n",
    "                    'sampling_rate': 250, 'reference': 'Common Average',\n",
    "                    'template': data['DATA_STRUCT']['template'].tolist(),\n",
    "                    'channels_interpolated': data['DATA_STRUCT']['pad_file'].tolist(),\n",
    "                    'added_channels': data['DATA_STRUCT']['template'] \\\n",
    "                                      [data['DATA_STRUCT']['pad_file']>0].tolist(),\n",
    "                    'labels' : {0: 'Control (C)', \n",
    "                                1: 'Frontotemporal Dementia (F)',\n",
    "                                2: 'Alzheimer (A)',\n",
    "                               },\n",
    "                   }\n",
    "    with open('AlzClassification/Summary/dataset_info.json', 'w') as json_file:\n",
    "        json.dump(dataset_info, json_file)        \n",
    "    for i in tqdm.tqdm(range(len(paths))):\n",
    "        data  = loadmat(paths[i], simplify_cells = True)\n",
    "        label = data['DATA_STRUCT']['label_group']\n",
    "        label = 0 if label=='C' else 1 if label=='F' else 2\n",
    "        eeg   = {'data': data['DATA_STRUCT']['data'], 'label': label }\n",
    "        with open(save_path + file_names[i].split('.')[0] + '.pickle', 'wb') as handle:\n",
    "            pickle.dump(eeg, handle, protocol = pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "\n",
    "# Task: Control - Parkinson's disease\n",
    "elif ds_code == 'ds002778':\n",
    "    data = loadmat(paths[0], simplify_cells = True)\n",
    "    np.save('PDClassification/Summary/ds002778/template.npy', \n",
    "            data['DATA_STRUCT']['template'])\n",
    "    np.save('PDClassification/Summary/ds002778/channels_interpolated.npy',\n",
    "            data['DATA_STRUCT']['pad_file'])\n",
    "    dataset_info = {'dataset_id': 8, 'tot_subjects': 31, 'tot_sessions': 1,\n",
    "                    'sampling_rate': 250, 'reference': 'Common Average',\n",
    "                    'template': data['DATA_STRUCT']['template'].tolist(),\n",
    "                    'channels_interpolated': data['DATA_STRUCT']['pad_file'].tolist(),\n",
    "                    'added_channels': data['DATA_STRUCT']['template'] \\\n",
    "                                      [data['DATA_STRUCT']['pad_file']>0].tolist(),\n",
    "                    'labels' : {0: 'Control (C)', 1: 'Parkinson (POFF)'},\n",
    "                   }\n",
    "    with open('PDClassification/Summary/ds002778/dataset_info.json', 'w') as json_file:\n",
    "        json.dump(dataset_info, json_file)        \n",
    "    for i in tqdm.tqdm(range(len(paths))):\n",
    "        data  = loadmat(paths[i], simplify_cells = True)\n",
    "        label = data['DATA_STRUCT']['label_group']\n",
    "        label = 0 if label=='C' else 1\n",
    "        eeg   = {'data': data['DATA_STRUCT']['data'], 'label': label }\n",
    "        with open(save_path + file_names[i].split('.')[0] + '.pickle', 'wb') as handle:\n",
    "            pickle.dump(eeg, handle, protocol = pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "\n",
    "# Task: Control - Parkinson's disease\n",
    "elif ds_code == 'ds003490':\n",
    "    data = loadmat(paths[0], simplify_cells = True)\n",
    "    np.save('PDClassification/Summary/ds003490/template.npy', \n",
    "            data['DATA_STRUCT']['template'])\n",
    "    np.save('PDClassification/Summary/ds003490/channels_interpolated.npy',\n",
    "            data['DATA_STRUCT']['pad_file'])\n",
    "    dataset_info = {'dataset_id': 5, 'tot_subjects': 50, 'tot_sessions': 1,\n",
    "                    'sampling_rate': 250, 'reference': 'Common Average',\n",
    "                    'template': data['DATA_STRUCT']['template'].tolist(),\n",
    "                    'channels_interpolated': data['DATA_STRUCT']['pad_file'].tolist(),\n",
    "                    'added_channels': data['DATA_STRUCT']['template'] \\\n",
    "                                      [data['DATA_STRUCT']['pad_file']>0].tolist(),\n",
    "                    'labels' : {0: 'Control (C)', 1: 'Parkinson (POFF)'},\n",
    "                   }\n",
    "    with open('PDClassification/Summary/ds003490/dataset_info.json', 'w') as json_file:\n",
    "        json.dump(dataset_info, json_file)        \n",
    "    for i in tqdm.tqdm(range(len(paths))):\n",
    "        data  = loadmat(paths[i], simplify_cells = True)\n",
    "        label = data['DATA_STRUCT']['label_group']\n",
    "        label = 0 if label=='C' else 1\n",
    "        eeg   = {'data': data['DATA_STRUCT']['data'], 'label': label }\n",
    "        with open(save_path + file_names[i].split('.')[0] + '.pickle', 'wb') as handle:\n",
    "            pickle.dump(eeg, handle, protocol = pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "# Task: Left Imagery - Right Imagery\n",
    "elif ds_code == 'ds004362':\n",
    "    data = loadmat(paths[0], simplify_cells = True)\n",
    "    np.save('MIClassification/Summary/template.npy', \n",
    "            data['DATA_STRUCT']['template'])\n",
    "    np.save('MIClassification/Summary/channels_interpolated.npy',\n",
    "            data['DATA_STRUCT']['pad_file'])\n",
    "    dataset_info = {'dataset_id': 25, 'tot_subjects': 106,\n",
    "                    'tot_sessions': 3, 'subject_excluded': [88, 92, 100],\n",
    "                    'sampling_rate': 160, 'reference': 'Common Average',\n",
    "                    'template': data['DATA_STRUCT']['template'].tolist(),\n",
    "                    'channels_interpolated': data['DATA_STRUCT']['pad_file'].tolist(),\n",
    "                    'added_channels': data['DATA_STRUCT']['template'] \\\n",
    "                                      [data['DATA_STRUCT']['pad_file']>0].tolist(),\n",
    "                    'labels' : {4: 'Left Hand Imagery (LHI)',\n",
    "                                5: 'Right Hand Imagery (RHI)'},\n",
    "                   }\n",
    "    with open('MIClassification/Summary/dataset_info.json', 'w') as json_file:\n",
    "        json.dump(dataset_info, json_file)        \n",
    "    for i in tqdm.tqdm(range(len(paths))):\n",
    "        data  = loadmat(paths[i], simplify_cells = True)\n",
    "        label = data['DATA_STRUCT']['label_group']\n",
    "        label = 0 if data['DATA_STRUCT']['label_map']=='LHI' else 1\n",
    "        if data['DATA_STRUCT']['label_map']!='LHI' and data['DATA_STRUCT']['label_map'] != 'RHI':\n",
    "            print('Wrong label')\n",
    "            break\n",
    "        eeg   = {'data': data['DATA_STRUCT']['data'], 'label': label }\n",
    "        with open(save_path + file_names[i].split('.')[0] + '.pickle', 'wb') as handle:\n",
    "            pickle.dump(eeg, handle, protocol = pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "# Task: First Episode Psychosis\n",
    "elif ds_code == 'ds003947':\n",
    "    data = loadmat(paths[0], simplify_cells = True)\n",
    "    np.save('FEPClassification/Summary/template.npy', \n",
    "            data['DATA_STRUCT']['template'])\n",
    "    np.save('FEPClassification/Summary/channels_interpolated.npy',\n",
    "            data['DATA_STRUCT']['pad_file'])\n",
    "    dataset_info = {'dataset_id': 7, 'tot_subjects': 61,\n",
    "                    'tot_sessions': 2, 'sampling_rate': 250,\n",
    "                    'reference': 'Common Average',\n",
    "                    'template': data['DATA_STRUCT']['template'].tolist(),\n",
    "                    'channels_interpolated': data['DATA_STRUCT']['pad_file'].tolist(),\n",
    "                    'added_channels': data['DATA_STRUCT']['template'] \\\n",
    "                                      [data['DATA_STRUCT']['pad_file']>0].tolist(),\n",
    "                    'labels' : {0: 'Control (C)',\n",
    "                                1: 'First Episode Psychosis (PSY)'},\n",
    "                   }\n",
    "    with open('FEPClassification/Summary/dataset_info.json', 'w') as json_file:\n",
    "        json.dump(dataset_info, json_file)        \n",
    "    for i in tqdm.tqdm(range(len(paths))):\n",
    "        data  = loadmat(paths[i], simplify_cells = True)\n",
    "        label = data['DATA_STRUCT']['label_group']\n",
    "        label = 0 if data['DATA_STRUCT']['label_group']=='C' else 1\n",
    "        if data['DATA_STRUCT']['label_pipeline'].casefold() != prepro_mode.casefold():\n",
    "            print('Wrong pipeline')\n",
    "            break\n",
    "        if data['DATA_STRUCT']['label_group']!='C' and data['DATA_STRUCT']['label_group'] != 'PSY':\n",
    "            print('Wrong label')\n",
    "            break\n",
    "        eeg   = {'data': data['DATA_STRUCT']['data'], 'label': label }\n",
    "        with open(save_path + file_names[i].split('.')[0] + '.pickle', 'wb') as handle:\n",
    "            pickle.dump(eeg, handle, protocol = pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "# Task: Sleep Deprivation\n",
    "elif ds_code == 'ds004902':\n",
    "    data = loadmat(paths[0], simplify_cells = True)\n",
    "    np.save('SleepClassification/Summary/template.npy', \n",
    "            data['DATA_STRUCT']['template'])\n",
    "    np.save('SleepClassification/Summary/channels_interpolated.npy',\n",
    "            data['DATA_STRUCT']['pad_file'])\n",
    "    dataset_info = {'dataset_id': 20, 'tot_subjects': 71,\n",
    "                    'tot_sessions': 2, 'sampling_rate': 250,\n",
    "                    'reference': 'Common Average',\n",
    "                    'template': data['DATA_STRUCT']['template'].tolist(),\n",
    "                    'channels_interpolated': data['DATA_STRUCT']['pad_file'].tolist(),\n",
    "                    'added_channels': data['DATA_STRUCT']['template'] \\\n",
    "                                      [data['DATA_STRUCT']['pad_file']>0].tolist(),\n",
    "                    'labels' : {0: 'Normal Sleep Eyes Open  (NSEO)',\n",
    "                                1: 'Sleep Deprivation Eyes Open (SDEO)'},\n",
    "                   }\n",
    "    with open('SleepClassification/Summary/dataset_info.json', 'w') as json_file:\n",
    "        json.dump(dataset_info, json_file)        \n",
    "    for i in tqdm.tqdm(range(len(paths))):\n",
    "        data  = loadmat(paths[i], simplify_cells = True)\n",
    "        label = data['DATA_STRUCT']['label_group']\n",
    "        label = 0 if data['DATA_STRUCT']['label_group']=='NSEO' else 1\n",
    "        if data['DATA_STRUCT']['label_group']!='NSEO' and data['DATA_STRUCT']['label_group'] != 'SDEO':\n",
    "            print('Wrong label')\n",
    "            break\n",
    "        eeg   = {'data': data['DATA_STRUCT']['data'], 'label': label }\n",
    "        with open(save_path + file_names[i].split('.')[0] + '.pickle', 'wb') as handle:\n",
    "            pickle.dump(eeg, handle, protocol = pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb7aeeb-c286-43b6-975e-149b808cc4c3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
